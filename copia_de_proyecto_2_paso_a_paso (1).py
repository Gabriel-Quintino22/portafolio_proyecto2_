# -*- coding: utf-8 -*-
"""Copia de Proyecto_2_Paso_a_Paso.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XkKc5j0hAHiTJzBfm9yuBGouAK2YcBy8

# Parte Regresiones (Excel)

* Priorizamos el uso de statsmodel, por especialidad en regresiones.
"""

# Cargamos las librerías
import pandas as pd                     #smf para trabajar modelos de regresion
import statsmodels.formula.api as smf   #sickitlearn es para machine learning
                                        #Minuto 10 del video es importante*

# Leemos los datos
datos = pd.read_excel("/content/Datos_Modelo.xlsx", sheet_name="Datos")  #Con pandas = pd llamamos a la funcion read_excel

# Revisamos el tipo de datos
datos.dtypes

# Aseguramos que la variable categórica esté tratada como tal
datos["Tamaño_Empresa"] = datos["Tamaño_Empresa"].astype("category") #Vamos a sobre escribir datos tamaño empresa
#pero ocuparemos la funcion astype para cambiar tamaño empresa de objeto a categorica

# Revisamos el tipo de datos
datos.dtypes

# ols = Ordinary Least Squares
# Modelo 1: Salario ~ Experiencia
modelo_1 = smf.ols('Salario ~ Experiencia', data=datos).fit()   #Con smf, llamamos a la funcion ols
                          #en data colocamos igual datos porque ahi asignacmos el nombre de nuestra base de datos"datos"
print(modelo_1.summary()) #y fit sirve para que haga el calculo/estimacion como tal

# Modelo 2: Salario ~ Experiencia + Años_Educación
modelo_2 = smf.ols('Salario ~ Experiencia + Años_Educación', data=datos).fit()
print(modelo_2.summary())

# Modelo 3: Salario ~ Experiencia + Años_Educación + Tamaño_Empresa (como factor)
modelo_3 = smf.ols('Salario ~ Experiencia + Años_Educación + C(Tamaño_Empresa)', data=datos).fit()
print(modelo_3.summary())

"""# Parte Machine Learning

* Implementaremos varios modelos de machine learning a la vez y en poco código.
* Priorizamos el uso de sklearn, por especialidad en machine learning.
* En Python se suele separar las variables predictoras de la predicha en dos dataset.
"""

# Cargamos las librerías necesarias
import pandas as pd  # Para manejo de datos en dataframes
from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba

# Modelos de regresión
from sklearn.linear_model import LinearRegression               # Regresión lineal
from sklearn.tree import DecisionTreeRegressor                  # Árbol de decisión
from sklearn.ensemble import RandomForestRegressor              # Random forest (conjunto de árboles)
from sklearn.neighbors import KNeighborsRegressor               # K-vecinos más cercanos (KNN)

# Métricas de evaluación del modelo
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Para cálculos numéricos adicionales
import numpy as np


#Como vi en R en los modelos de machine learning esta dividido en partes las variables x (independientes); Experiencia
#años_educacion, tamaño_empresa_certificaciones y una variable dependendiente, y; salario, para las variables x tenemos
#entrenamiento y testeo. Para y tenemos entrenamiento y testeo.

# Leemos el archivo Excel
datos = pd.read_excel("/content/Datos_Modelo.xlsx", sheet_name="Datos")
datos.head()
#DATO IMPORTANTE*: cuando trabajamos con Python y queremos seleccionar variableS(plural) a un vector se le asigna a un
#vector en mayuscula por ejemplo: X, mientras que si en una variable que se le quiere asignar un vector le colocamos
#en minuscula: y.

# Revisamos los tipos de datos
datos.dtypes

# Convertimos la variable categórica a tipo categoría
datos["Tamaño_Empresa"] = datos["Tamaño_Empresa"].astype("category")

# Revisamos los tipos de datos
datos.dtypes

# Definimos las variables predictoras
X = datos.drop(columns="Salario")  #la funcion drop sirve para eliminar columnas. En estricto rigor en este codigo
                                  #le decimos agarra nuestro archivo excel o df y elimina la columna "salario"

X.dtypes

# Revisamos las columnas
X.columns
#Aca puedo revisar las columnas que tenemos en X, ya que las habiamos asignado ahi.

# Variables predictoras con Tamaño_Empresa codificada
X = pd.get_dummies(X, drop_first=True)  # One-hot encoding para variables categóricas, precisamente para darle valor
#a las categorias, que vienen siendo en este ejemplo el tamaño de la empresa; no es lo mismo una mediana que una pequeña
#Aun asi se elimino la grande por "drop_firts=True" pero no es que deje de existir como tal, sino mas bien es porque
#la empresa grande es ocupada como categoria de referencia o dummies

# Revisamos las columnas
X.dtypes
#Con este codigo podremos ver si en el df a la categoria empresa la dejamos distinguida entre mediana y pequeña

# Creamos la columna de variable dependiente
y = datos["Salario"]

# Revisamos los tipos de datos
y.dtypes

# Separamos los datos en entrenamiento y prueba (creamos 4 dataset) = X e y, entrenamiento y testeo
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
#Aca a diferencia de R vamos a comenzar haciendo el de testeo y le colocamos 0.2 es decir el 20%, mientras que
#el 0.8, es decir el 80% va para el entrenamiento y el random state, es como en R el set.seed,  para que se repita
#el modelo de testeo pero que al arrojar el codigo una y otra vez salga el mismo resultado

#Y como tenemos 4 dataset: (lo colocare en español el codigo): X_entrenamiento, X_testeo, y_ entrenamiento, y_testeo

# Inicializamos los modelos (almacenamos los modelos para uso futuro)
modelos = {
    "Regresión Lineal": LinearRegression(),   #guardamos lo que esta en comilla con las funciones que estan en blanco
    "Árbol de Decisión": DecisionTreeRegressor(random_state=123),  #aca tambien ocupamos random_state precisamente
                                                                   #para que queden estables los resultados
    "Random Forest": RandomForestRegressor(random_state=123), #Esto pasa con los modelos de arboles y RF
    "KNN": KNeighborsRegressor()
}

modelos["Random Forest"]

"""## Ejemplo en modelo de regresión lineal simple"""

# Entrenamos el modelo de Regresión Lineal (usamos uno de los 4 modelos que almacenamos)
modelo_rl = modelos["Regresión Lineal"]
modelo_rl.fit(X_train, y_train)   #Entrenando los modelos de entrenamiento X e y.

# Realizamos las predicciones (con la data de testeo)
predicciones = modelo_rl.predict(X_test)
predicciones

# Calculamos métricas (indicamos predicciones y datos reales testeo)
r2 = r2_score(y_test, predicciones) # estas predicciones las hicimos
                    #Nosotros teniamos dos datas, data de entrenamiento, data de testeo, con la
                 #data de entrenamiento nosotros entrenamos un modelo que funciona, luego fuimos con este modelo
                # buscamos los x de testeo, con ese x de testeo hicimos una predicccion, y esa predicccion con esos x
                # de testeo los vamos a
                #contrastar con el y de testeo, esta prediccion viene del modleo de entrenamiento mezclado con los x
                                                #de testeo nos da una prediccion y luego paramos con el y de testeo.
mae = mean_absolute_error(y_test, predicciones)
rmse = np.sqrt(mean_squared_error(y_test, predicciones))

# Mostramos resultados
print(r2)
print(mae)
print(rmse)

modelos                     #Importante dato minuto -11:00*

# Recorramos todos los modelos creados    #Ahora haremos un ciclo donde pasen todos los modelos para las distintas
                                          #pruebas de metricas que tenemos
for nombre, modelo in modelos.items():
  print(nombre + "  ---  " + str(modelo))  #Y al implementar este codigo de ahi en la consola nos dara un resultado que
                                           # tenga el nombre al lado izquiero y al lado derecho el modelo

"""## Proyecto Final

* Tomaremos todos los contenidos vistos, y mediante un ciclo implementaremos los 4 modelos a la vez.
"""

# Creamos una lista vacía para almacenar las futuras métricas de resultados
resultados = []

# Obtenemos los resultados de los modelos
for nombre, modelo in modelos.items():

    # Ajustamos el modelo con los datos de entrenamiento
    modelo.fit(X_train, y_train)

    # Realizamos las predicciones para los datos de testeo
    pred = modelo.predict(X_test)

    # Obtenemos las métricas para los datos de testeo
    r2 = r2_score(y_test, pred)
    mae = mean_absolute_error(y_test, pred)
    rmse = np.sqrt(mean_squared_error(y_test, pred))


    # Añadimos los resultados al dataframe
    resultados.append({
        "Modelo": nombre,
        "R2": r2,
        "MAE": mae,
        "RMSE": rmse
    })

# Mostramos los resultados
df_resultados = pd.DataFrame(resultados)
print(df_resultados)

"""## Conclusiones

* Python nos ofrece todo para implementar modelos de machine learning.
* Lo que vimos es una pequeña parte de todo lo que se puede hacer.
* Puedes reutilizar 100% este código y mejorarlo.
"""